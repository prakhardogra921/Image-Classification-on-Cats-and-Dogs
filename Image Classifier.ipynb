{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras import optimizers\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dir = \"train/train/\"\n",
    "new_train_dir = \"train/new_train\"\n",
    "validation_dir = 'train/validation'\n",
    "img_width, img_height = 150, 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    im = Image.open(train_dir + \"/\" + file)\n",
    "    img = im.resize((img_width, img_height))\n",
    "    #gray = img.convert(\"L\")\n",
    "    #gray.save(new_train_dir + \"/\" + file)\n",
    "    img.save(new_train_dir + \"/\" + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    im = Image.open(test_dir + \"/\" + file)\n",
    "    img = im.resize((img_width, img_height))\n",
    "    gray = img.convert(\"L\")\n",
    "    gray.save(new_test_dir + \"/\" + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# used to rescale the pixel values from [0, 255] to [0, 1] interval\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# automagically retrieve images and their classes for train and validation sets\n",
    "train_gen = datagen.flow_from_directory(\n",
    "        new_train_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=16,\n",
    "        class_mode='binary')\n",
    "validation_gen = datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=16,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Model\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32,(3,3), input_shape = (img_width, img_height, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Convolution2D(32,(3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64,(3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "#Dropout to prevent overfitting\n",
    "model.add(Flatten()) #flatten feature map into 1 dimension\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#final layer to predict probabilities\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#perform gradient descent\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = \"rmsprop\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python35\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_steps=5000, steps_per_epoch=1250, validation_data=<keras.pre..., epochs=1)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1250/1250 [==============================] - 1245s - loss: 0.4429 - acc: 0.8126 - val_loss: 0.4431 - val_acc: 0.8154\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_gen, steps_per_epoch = 20000, nb_epoch = 1, validation_data = validation_gen, nb_val_samples = 5000)\n",
    "model.save_weights('models/basic_cnn_20_epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
